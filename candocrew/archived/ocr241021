"""OCR_20241021.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p4mMSzblQvNGZV-xn0JXIbGUOzPrgF2q
"""

# -*- coding: utf-8 -*-
"""OCR_20241019.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14YOgSRx2Qj-LBLbFDPViMHLlOFlGeJcG
"""

# Installer
"""!sudo apt-get install tesseract-ocr
!pip install pytesseract
!pip install python-dateutil
from google.colab import drive
drive.mount('/content/drive')"""

import json
import os
import re

import cv2
import matplotlib.pyplot as plt
import numpy as np
import pytesseract as pyt
import torch.nn as nn
import torchvision.transforms as transforms
from dateutil import parser
from PIL import Image
from PIL import Image as Img
from torchvision import models

pyt.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

desired_format = "%Y/%m/%d"
image_dir = "/content/drive/MyDrive/PaymentReceipt/dataset/test_Data/KBZ"
# 2024/10/21 HNDW Start
# Classification model path
model_dir = "/content/drive/My Drive/PaymentReceipt/model/vgg16/vgg16_bn_03.pth"
# 2024/10/21 HNDW End
class_labels = ["AYAPay", "CBPay", "KPay", "Other", "WavePay"]

# Regular expression patterns for extracting fields
transtype_pattern = re.compile(r"^(Transaction Type|Type)\s?:?\s?(.+)")
notes_pattern = re.compile(r"^(Notes|Note|Purpose|Reason)\s?:?\s?(.+)")
transtime_pattern = re.compile(
    r"^(Transaction Time|Date and Time|Date & Time|Transaction Date)\s?:?\s?(.+)"
)
transno_pattern = re.compile(
    r"^(Transaction No|Transaction ID|Transaction IO|Invoice No)\s?:?\s?(.+)"
)
receiver_pattern = re.compile(r"^(To|Receiver Name|Send To)\s?:?\s?(.+)")
sender_pattern = re.compile(r"^(From|Sender Name|Send From)\s?:?\s?(.+)")
amount_data_pattern = re.compile(r"^(Amaunt|Amount|Total Amount)\s?:?\s?(.+)")
amount_only_pattern = re.compile(r"(\d*(?:,\d*)*(?:\.\d*)?)\s?(MMK|Ks)$")


def extract_text_from_image(image_path):
    """
    Extracts text from an image using Tesseract OCR.

    :param image_path: Path to the image file
    :return: Extracted text as a string, or None if extraction fails
    """
    try:
        # Read the image using OpenCV
        img = cv2.imread(image_path)

        if img is None:
            raise ValueError(f"Failed to read image: {image_path}")

        # Convert the image to grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # Apply a Gaussian blur to reduce noise and smoothen the image
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)

        # Increase contrast using adaptive histogram equalization (CLAHE)
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        enhanced_img = clahe.apply(blurred)

        # Sharpen the image to make text more readable
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
        sharpened = cv2.filter2D(enhanced_img, -1, kernel)

        # Apply a threshold to convert the image to binary (black and white)
        # Adjust the threshold value to ensure better extraction of gray text
        _, thresh = cv2.threshold(
            sharpened, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )

        # Inpainting to remove the watermark
        # result = cv2.inpaint(img, thresh, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

        # Convert back to a PIL image
        pil_image = Img.fromarray(thresh)

        # Use Tesseract to do OCR on the image
        config = "--psm 6 --oem 3"
        text = pyt.image_to_string(thresh, config=config, lang="eng")
        return text

    except Exception as e:
        print(f"Error processing image {image_path}: {e}")
        return None


# Split text into lines
def split_text_into_lines(text):
    lines = text.split("\n")
    return [line.strip() for line in lines if line.strip()]


def extract_date_time(date_time_str):
    """
    Extracts date and time from the input string using regex and dateutil parser.

    :param date_time_str: String containing date and time
    :return: Tdate, time
    """

    # Define regular expressions to match different date and time formats
    date_pattern = re.compile(
        r"(\d{8})|(\d{1,2}[/-]\d{1,2}[/-]\d{2,4}|\d{1,2} \w+ \d{4}|\w+ \d{1,2}, \d{4})"
    )
    time_pattern = re.compile(
        r"\b((1[0-2]|0?[1-9]):[0-5][0-9](?::[0-5][0-9])?\s?[APap][Mm]|(2[0-3]|[01]?[0-9]):[0-5][0-9](?::[0-5][0-9])?)\b"
    )

    try:
        # Search date and time matches in the input string
        date_match = date_pattern.search(date_time_str)
        times_match = time_pattern.search(date_time_str)

        # Parse the date part
        try:
            if date_match:
                date_obj = parser.parse(date_match.group())
                formatted_date = date_obj.strftime("%Y/%m/%d")
            else:
                formatted_date = ""
        except:
            formatted_date = ""

        # Parse the time part
        try:
            if times_match:
                time_obj = parser.parse(times_match.group())
                formatted_time = time_obj.strftime("%H:%M:%S")
            else:
                formatted_time = ""
        except:
            formatted_time = ""

    except Exception as e:
        print(f"Error parsing date or time: {e}")

    return formatted_date, formatted_time


def extract_amount_only(amount_str):
    """
    Extracts numeric amount from the amount string using regex.

    :param amount_str: amount with negative sign, MMK, Ks
    :return: numeric amount as a string
    """

    formatted_amount = amount_str
    amount_pattern = re.compile(r"-?\d*(?:,\d*)*(?:\.\d{2})?")
    amount_pattern_match = amount_pattern.search(amount_str)

    if amount_pattern_match:
        return amount_pattern_match.group().replace("-", "").strip()

    return amount_str


def extract_transaction_data(text):
    amount_only_extracted = ""
    transaction_data = {
        "Transaction No": None,
        "Date": None,
        "Time": None,
        "Transaction Time": None,
        "Transaction Type": None,
        "Sender Name": None,
        "Amount": None,
        "Receiver Name": None,
        "Notes": None,
    }
    lines = split_text_into_lines(text)
    for line in lines:
        # Transaction Time
        if re.search(transtime_pattern, line):
            transtime_pattern_match = transtime_pattern.search(line)
            date_time_str = transtime_pattern_match.group(2).strip().strip("@").strip()
            transaction_data["Transaction Time"] = date_time_str
            transaction_data["Date"], transaction_data["Time"] = extract_date_time(
                date_time_str
            )

        # Transaction No
        elif re.search(transno_pattern, line):
            transno_pattern_match = transno_pattern.search(line)
            transaction_data["Transaction No"] = (
                transno_pattern_match.group(2).strip().strip("@").strip()
            )

        # Transaction Type
        elif re.search(transtype_pattern, line):
            transtype_pattern_match = transtype_pattern.search(line)
            transaction_data["Transaction Type"] = (
                transtype_pattern_match.group(2).strip().strip("@").strip()
            )

        # Amounts
        elif re.search(amount_data_pattern, line):
            amount_data_pattern_match = amount_data_pattern.search(line)
            amount_string = (
                amount_data_pattern_match.group(2).strip().strip("@").strip()
            )
            transaction_data["Amount"] = extract_amount_only(amount_string)

        # Sender Name
        elif re.search(sender_pattern, line):
            sender_pattern_match = sender_pattern.search(line)
            transaction_data["Sender Name"] = (
                sender_pattern_match.group(2).strip().strip("@").strip()
            )

        # Receiver Name
        elif re.search(receiver_pattern, line):
            receiver_pattern_match = receiver_pattern.search(line)
            transaction_data["Receiver Name"] = (
                receiver_pattern_match.group(2).strip().strip("@").strip()
            )

        # Notes
        elif re.search(notes_pattern, line):
            notes_match = notes_pattern.search(line)
            transaction_data["Notes"] = notes_match.group(2).strip()

        # Amount (if Amount Field does not exist.)
        elif re.search(amount_only_pattern, line):
            amount_only_pattern_match = amount_only_pattern.search(line)
            amount_only_extracted = (
                amount_only_pattern_match.group(1).replace("-", "").strip()
            )

    if transaction_data["Amount"] == None:
        transaction_data["Amount"] = amount_only_extracted

    return transaction_data


# 2024/10/21 HNDW Start for classification
# load and preprocess the image for classification
def processing_image(image_path):
    # Load the image
    img = Image.open(image_path)

    # Define preprocessing steps
    img_transform = transforms.Compose(
        [
            transforms.Resize(224),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    # Apply preprocessing
    img_transform = img_transform(img)  # torch.Size([3, 224, 224])
    inputs = img_transform.unsqueeze(0)  # torch.Size([1, 3, 224, 224])

    return inputs


def predict_class(model, image_path, class_names):
    # Check for GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Switch to evaluation mode
    model.eval()

    with torch.no_grad():
        dir, fileName = os.path.split(image_path)
        data = processing_image(image_path)
        input_data = data.to(device)

        # Check input shape
        print("Input data shape:", input_data.shape)  # Debugging line

        # Make predictions
        predicted = model(input_data)

        # Get the predicted class
        _, pred_label = torch.max(predicted, 1)

        # Convert index to class name
        label_name = class_names[pred_label.item()]

        # Display the image
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(image_rgb)
        plt.axis("off")  # Hide axis
        plt.show()

        return label_name


# Load the pre-trained model
model = models.vgg16_bn(pretrained=True)  # Load the VGG model with pre-trained weights
model.classifier[6] = nn.Linear(4096, len(class_labels))  # Update the classifier layer
model.load_state_dict(torch.load(model_dir))  # Load your trained model weights
# 2024/10/21 HNDW End for classification model load

# Process images and save extracted data to JSON
all_transactions = []

for filename in os.listdir(image_dir):
    if filename.lower().endswith((".png", ".jpg", ".jpeg")):
        image_path = os.path.join(image_dir, filename)

        try:
            # Extract text using Tesseract
            extracted_text = extract_text_from_image(image_path)
            print(f"Extracted data from {filename}")
            # print(f"Extracted data from {filename}: \n{extracted_text}\n")

            # Extract transaction information using regex
            transaction_info = extract_transaction_data(extracted_text)
            transaction_info["File"] = filename  # Optional: Add filename for reference
            # 2024/10/21 HNDW Start
            transaction_info["Payment Type"] = predict_class(
                model, image_path, class_labels
            )  # Image Classification
            # 2024/10/21 HNDW End
            print(transaction_info)

            # Add to list of all transactions
            all_transactions.append(transaction_info)

        except Exception as e:
            print(f"Failed to process {filename}: {e}")

# Save the extracted transaction data to a JSON file
output_json_path = "transactions_data.json"
with open(output_json_path, "w") as json_file:
    json.dump(all_transactions, json_file, indent=4)

print(f"All data saved to {output_json_path}")
